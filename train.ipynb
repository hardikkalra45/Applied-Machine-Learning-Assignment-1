{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "from textblob import TextBlob\n",
        "import pandas\n",
        "import sklearn\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "outputs": [],
      "metadata": {
        "id": "a1vrHkejaJTD"
      },
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_data = pd.read_csv(\"/content/drive/My Drive/train_data.csv\")\n",
        "val_data = pd.read_csv(\"/content/drive/My Drive/val_data.csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/My Drive/test_data.csv\")\n",
        "messages = train_data"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiToLNWeaJTE",
        "outputId": "431228d0-49db-4233-a49a-c3746fc55710"
      },
      "execution_count": 92
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 3: Data to vectors"
      ],
      "metadata": {
        "id": "x7bNARDjaJTN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll convert each message, represented as a list of tokens (lemmas) above, into a vector that machine learning models can understand.\n",
        "\n",
        "Doing that requires essentially three steps, in the bag-of-words model:\n",
        "\n",
        "1. counting how many times does a word occur in each message (term frequency)\n",
        "2. weighting the counts, so that frequent tokens get lower weight (inverse document frequency)\n",
        "3. normalizing the vectors to unit length, to abstract from the original text length (L2 norm)"
      ],
      "metadata": {
        "id": "BKuoj4YcaJTN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each vector has as many dimensions as there are unique words in the corpus:"
      ],
      "metadata": {
        "id": "QwKCh9sRaJTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow_transformer = CountVectorizer(analyzer=split_into_lemmas).fit(messages['text'])\n",
        "print(len(bow_transformer.vocabulary_))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31303\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kwxnfaCaJTN",
        "outputId": "b45eb299-ae15-4375-bf28-40aa281395e8"
      },
      "execution_count": 93
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we used `scikit-learn` (`sklearn`), a powerful Python library for teaching machine learning. It contains a multitude of various methods and options.\n",
        "\n",
        "Let's take one text message and get its bag-of-words counts as a vector, putting to use our new `bow_transformer`:"
      ],
      "metadata": {
        "id": "7JisNjDeaJTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages_bow = bow_transformer.transform(messages['text'])\n",
        "val_data_bow = bow_transformer.transform(val_data['text'])\n",
        "test_data_bow = bow_transformer.transform(test_data['text'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "YIFs87zLaJTO"
      },
      "execution_count": 94
    },
    {
      "cell_type": "markdown",
      "source": [
        "And finally, after the counting, the term weighting and normalization can be done with [TF-IDF](http://en.wikipedia.org/wiki/Tf%E2%80%93idf), using scikit-learn's `TfidfTransformer`:"
      ],
      "metadata": {
        "id": "Pw52x5zgaJTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_transformer_train = TfidfTransformer().fit(messages_bow)\n",
        "tfidf_transformer_val = TfidfTransformer().fit(val_data_bow)\n",
        "tfidf_transformer_test = TfidfTransformer().fit(test_data_bow)"
      ],
      "outputs": [],
      "metadata": {
        "id": "k1zqyZIoaJTO"
      },
      "execution_count": 95
    },
    {
      "cell_type": "markdown",
      "source": [
        "To transform the entire bag-of-words corpus into TF-IDF corpus at once:"
      ],
      "metadata": {
        "id": "Q1ZpqIrraJTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages_tfidf = tfidf_transformer_train.transform(messages_bow)\n",
        "val_tfidf = tfidf_transformer_val.transform(val_data_bow)\n",
        "test_tfidf = tfidf_transformer_test.transform(test_data_bow)"
      ],
      "outputs": [],
      "metadata": {
        "id": "dbM4w7xJaJTP"
      },
      "execution_count": 96
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 4: Training, evaluating and testing model 1 (Multinomial NB)\n",
        "\n"
      ],
      "metadata": {
        "id": "KeFrAVkuaJTP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With messages represented as vectors, we can finally train our spam-or-not classifier. This part is pretty straightforward, and there are many libraries that realize the training algorithms."
      ],
      "metadata": {
        "id": "L8DI9OoxaJTP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll be using scikit-learn here, choosing the [Naive Bayes](http://en.wikipedia.org/wiki/Naive_Bayes_classifier) classifier to start with:"
      ],
      "metadata": {
        "id": "az2BXEkGaJTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spam_detector = MultinomialNB().fit(messages_tfidf, messages['spam'])\n",
        "all_predictions = spam_detector.predict(messages_tfidf)"
      ],
      "outputs": [],
      "metadata": {
        "id": "KU1SWq28aJTP"
      },
      "execution_count": 97
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAIN DATA\n",
        "print('accuracy', accuracy_score(messages['spam'], all_predictions))\n",
        "print('confusion matrix\\n', confusion_matrix(messages['spam'], all_predictions))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.9339048048725468\n",
            "confusion matrix\n",
            " [[3355    0]\n",
            " [ 293  785]]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j45w088aJTQ",
        "outputId": "0deb6f1b-73f0-4dfd-a7a4-87c967e778b5"
      },
      "execution_count": 98
    },
    {
      "cell_type": "code",
      "source": [
        "all_predictions = spam_detector.predict(val_tfidf)"
      ],
      "metadata": {
        "id": "G-YbURCFmawS"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VALIDATION DATA\n",
        "print('accuracy', accuracy_score(val_data['spam'], all_predictions))\n",
        "print('confusion matrix\\n', confusion_matrix(val_data['spam'], all_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoFJhnfqmbRA",
        "outputId": "940bab52-02b8-42e7-ecf9-69b3233c7752"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.8898601398601399\n",
            "confusion matrix\n",
            " [[424   0]\n",
            " [ 63  85]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_predictions = spam_detector.predict(test_tfidf)"
      ],
      "metadata": {
        "id": "rJtBGiiPm5WM"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST DATA\n",
        "print('accuracy', accuracy_score(test_data['spam'], all_predictions))\n",
        "print('confusion matrix\\n', confusion_matrix(test_data['spam'], all_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hc2Md9Hm5zc",
        "outputId": "e6c5880b-aa74-4303-b95d-b218e0c3ce1d"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.868421052631579\n",
            "confusion matrix\n",
            " [[428   0]\n",
            " [ 75  67]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 4: Training, evaluating and testing model 2 (RandomForestClassifier)"
      ],
      "metadata": {
        "id": "_Bf70L7YqwUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "spam_detector = RandomForestClassifier(random_state = 69).fit(messages_tfidf, messages['spam'])\n",
        "all_predictions = spam_detector.predict(messages_tfidf)"
      ],
      "metadata": {
        "id": "K0JYgjbSnRBs"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAIN DATA\n",
        "print('accuracy', accuracy_score(messages['spam'], all_predictions))\n",
        "print('confusion matrix\\n', confusion_matrix(messages['spam'], all_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNwmDNGonreh",
        "outputId": "01f55674-02f6-4c0b-d0aa-d118b1961d2a"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 1.0\n",
            "confusion matrix\n",
            " [[3355    0]\n",
            " [   0 1078]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VALIDATION DATA\n",
        "all_predictions = spam_detector.predict(val_tfidf)\n",
        "print('accuracy', accuracy_score(val_data['spam'], all_predictions))\n",
        "print('confusion matrix\\n', confusion_matrix(val_data['spam'], all_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLafyQ-qn2nn",
        "outputId": "d6a5ba02-14d3-46b9-c4f0-37fd5be649b4"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.9772727272727273\n",
            "confusion matrix\n",
            " [[424   0]\n",
            " [ 13 135]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST DATA\n",
        "all_predictions = spam_detector.predict(test_tfidf)\n",
        "print('accuracy', accuracy_score(test_data['spam'], all_predictions))\n",
        "print('confusion matrix\\n', confusion_matrix(test_data['spam'], all_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU0bWf6cn228",
        "outputId": "bae0de3d-ec4b-4ef9-b83b-67f2e9f536a6"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.9771929824561404\n",
            "confusion matrix\n",
            " [[427   1]\n",
            " [ 12 130]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 4: Training, evaluating and testing model 3 (Support Vector Machines)"
      ],
      "metadata": {
        "id": "rQCNiEQlq8hC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "spam_detector = SVC(random_state = 69).fit(messages_tfidf, messages['spam'])\n",
        "all_predictions = spam_detector.predict(messages_tfidf)"
      ],
      "metadata": {
        "id": "YSCnFAICn3OL"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAIN DATA\n",
        "print('accuracy', accuracy_score(messages['spam'], all_predictions))\n",
        "print('confusion matrix\\n', confusion_matrix(messages['spam'], all_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33ae898a-3916-4a25-b0b7-26cb8edfd760",
        "id": "sT0S1-_0omXL"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 1.0\n",
            "confusion matrix\n",
            " [[3355    0]\n",
            " [   0 1078]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VALIDATION DATA\n",
        "all_predictions = spam_detector.predict(val_tfidf)\n",
        "print('accuracy', accuracy_score(val_data['spam'], all_predictions))\n",
        "print('confusion matrix\\n', confusion_matrix(val_data['spam'], all_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11587442-d9d4-474f-ea2b-d4f3d9fbbb78",
        "id": "2wkHcujLouQ9"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.9877622377622378\n",
            "confusion matrix\n",
            " [[423   1]\n",
            " [  6 142]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST DATA\n",
        "all_predictions = spam_detector.predict(test_tfidf)\n",
        "print('accuracy', accuracy_score(test_data['spam'], all_predictions))\n",
        "print('confusion matrix\\n', confusion_matrix(test_data['spam'], all_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7763f59-12ca-40e0-f2b3-d9f30c4fa789",
        "id": "FgIqriuoozRa"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.987719298245614\n",
            "confusion matrix\n",
            " [[427   1]\n",
            " [  6 136]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Best model is SVM model with 98.77% accuracy on test data.**"
      ],
      "metadata": {
        "id": "aBFz_zPKvFrq"
      }
    }
  ]
}